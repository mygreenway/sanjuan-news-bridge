# -*- coding: utf-8 -*-
# Noticias Espa√±a Bot ‚Äî main.py
# –ó–∞–¥–∞—á–∏:
# - —á–∏—Ç–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ RSS
# - —Ç—è–Ω—É—Ç—å —Ç–µ–∫—Å—Ç –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
# - –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—å/—Å–∂–∏–º–∞—Ç—å –Ω–æ–≤–æ—Å—Ç—å –Ω–∞ —Ä—É—Å—Å–∫–∏–π —á–µ—Ä–µ–∑ OpenAI
# - –ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å –≤ –∫–∞–Ω–∞–ª –≤ –Ω—É–∂–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ (HTML)
# - –∑–∞—â–∏—Ç–∞ –æ—Ç –¥—É–±–ª–µ–π (SQLite)

import os
import re
import html
import time
import json
import asyncio
import logging
import hashlib
import sqlite3
from datetime import datetime, timedelta, timezone
from urllib.parse import urlparse, urlunparse

import feedparser
import requests
import trafilatura

from telegram import Bot
from telegram.constants import ParseMode

# ---------------------------- CONFIG ----------------------------
CHANNEL = "@NoticiasEspanaHoy"  # –º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ numeric id
CHECK_INTERVAL_MIN = 30         # —Ä–∞–∑ –≤ N –º–∏–Ω—É—Ç –ø—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏
DB_PATH = "state.db"
HTTP_TIMEOUT = 15
USER_AGENT = "NoticiasEspanaBot/1.0 (+https://t.me/NoticiasEspanaHoy)"

# RSS-–∏—Å—Ç–æ—á–Ω–∏–∫–∏ (–º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä—è—Ç—å/–º–µ–Ω—è—Ç—å)
RSS_FEEDS = [
    "https://elpais.com/rss/elpais/portada.xml",
    "https://e00-elmundo.uecdn.es/elmundo/rss/portada.xml",
    "https://www.20minutos.es/rss/",
    "https://www.abc.es/rss/feeds/abc_ultima.xml",
    "https://www.rtve.es/api/rss/portada",
    # –ö–æ—Å—Ç–∞-–ë–ª–∞–Ω–∫–∞ / –í–∞–ª–µ–Ω—Å–∏—è (–º–æ–≥—É—Ç –º–µ–Ω—è—Ç—å—Å—è, –±–æ—Ç –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–µ)
    "https://www.informacion.es/rss/section/1056",
    "https://www.levante-emv.com/rss/section/13069",
    "https://www.lasprovincias.es/rss/2.0/portada",  # –ø—Ä–∏–º–µ—Ä
]

# OpenAI (–¥–ª—è —Ç–≤–æ–µ–π –≤–µ—Ä—Å–∏–∏ openai==1.17.0)
from openai import OpenAI
OPENAI_MODEL = "gpt-4o-mini"  # –º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ gpt-4o, –µ—Å–ª–∏ –µ—Å—Ç—å –¥–æ—Å—Ç—É–ø

# ---------------------------- LOGGING ----------------------------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s"
)
log = logging.getLogger("noticias-espana")

# ---------------------------- UTILS ----------------------------
def normalize_url(u: str) -> str:
    try:
        p = urlparse(u)
        # —É–±–∏—Ä–∞–µ–º —Ç—Ä–µ–∫–∏–Ω–≥
        clean_query = "&".join(sorted([q for q in p.query.split("&") if q and not q.lower().startswith(("utm_", "fbclid"))]))
        p = p._replace(query=clean_query)
        norm = urlunparse(p)
        return norm
    except Exception:
        return u

def sha256(s: str) -> str:
    return hashlib.sha256(s.encode("utf-8", "ignore")).hexdigest()

def ensure_db():
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute("""
        CREATE TABLE IF NOT EXISTS posts(
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            url_hash TEXT UNIQUE,
            title_hash TEXT,
            source_url TEXT,
            title TEXT,
            created_at INTEGER
        )
    """)
    c.execute("CREATE INDEX IF NOT EXISTS idx_created_at ON posts(created_at)")
    conn.commit()
    conn.close()

def seen(url: str, title: str) -> bool:
    url_h = sha256(normalize_url(url))
    title_h = sha256(title.strip().lower())
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute("SELECT 1 FROM posts WHERE url_hash=? OR title_hash=?", (url_h, title_h))
    row = c.fetchone()
    conn.close()
    return row is not None

def mark_seen(url: str, title: str):
    url_h = sha256(normalize_url(url))
    title_h = sha256(title.strip().lower())
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute("INSERT OR IGNORE INTO posts(url_hash, title_hash, source_url, title, created_at) VALUES (?,?,?,?,?)",
              (url_h, title_h, url, title, int(time.time())))
    conn.commit()
    conn.close()

def cleanup_db(days: int = 7):
    cutoff = int((datetime.now(timezone.utc) - timedelta(days=days)).timestamp())
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute("DELETE FROM posts WHERE created_at < ?", (cutoff,))
    conn.commit()
    conn.close()

# ---------------------------- FETCHING ----------------------------
session = requests.Session()
session.headers.update({"User-Agent": USER_AGENT})

def fetch_url(url: str) -> requests.Response:
    return session.get(url, timeout=HTTP_TIMEOUT, allow_redirects=True)

def extract_main_image(html_text: str, base_url: str) -> str | None:
    # –ø—ã—Ç–∞–µ–º—Å—è –≤—ã—Ç–∞—â–∏—Ç—å og:image
    try:
        og = re.search(r'<meta[^>]+property=["\']og:image["\'][^>]+content=["\']([^"\']+)["\']', html_text, re.IGNORECASE)
        if og:
            return og.group(1)
    except Exception:
        pass
    # –∫–∞–∫ fallback ‚Äî –ø–µ—Ä–≤–∞—è –∫–∞—Ä—Ç–∏–Ω–∫–∞ –∏–∑ —Å—Ç–∞—Ç—å–∏
    try:
        m = re.search(r'<img[^>]+src=["\']([^"\']+)["\']', html_text, re.IGNORECASE)
        if m:
            return m.group(1)
    except Exception:
        pass
    return None

def extract_text(url: str) -> tuple[str | None, str | None]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (—Ç–µ–∫—Å—Ç_—Å—Ç–∞—Ç—å–∏, url_–∫–∞—Ä—Ç–∏–Ω–∫–∏)
    """
    try:
        r = fetch_url(url)
        if r.status_code != 200 or not r.text:
            return None, None
        downloaded = trafilatura.extract(r.text, include_comments=False, include_images=False, url=url)
        # downloaded ‚Äî —É–∂–µ ¬´—á–∏—Å—Ç—ã–π¬ª —Ç–µ–∫—Å—Ç; –º–æ–∂–µ—Ç –±—ã—Ç—å None
        img = extract_main_image(r.text, url)
        return downloaded, img
    except Exception as e:
        log.warning(f"extract_text error: {e}")
        return None, None

# ---------------------------- OPENAI ----------------------------
def build_prompt(title_es: str, body_es: str) -> list[dict]:
    system = (
        "–¢—ã –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫-—Ä–µ–¥–∞–∫—Ç–æ—Ä. –ü–µ—Ä–µ–≤–µ–¥–∏ –∏ —Å–æ–∂–º–∏ –Ω–æ–≤–æ—Å—Ç—å —Å –∏—Å–ø–∞–Ω—Å–∫–æ–≥–æ –Ω–∞ —Ä—É—Å—Å–∫–∏–π. "
        "–ü—Ä–∞–≤–∏–ª–∞: —Ñ–∞–∫—Ç—ã –±–µ–∑ –∏—Å–∫–∞–∂–µ–Ω–∏–π, —Ü–∏—Ñ—Ä—ã/–∏–º–µ–Ω–∞/–¥–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å, –Ω–∏–∫–∞–∫–∏—Ö –¥–æ–º—ã—Å–ª–æ–≤. "
        "–°—Ç—Ä—É–∫—Ç—É—Ä–∞: 2‚Äì4 –∫–æ—Ä–æ—Ç–∫–∏—Ö –∞–±–∑–∞—Ü–∞; –ø–µ—Ä–≤—ã–π –∞–±–∑–∞—Ü –ù–ï –¥—É–±–ª–∏—Ä—É–µ—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫ –ø–æ —Å–º—ã—Å–ª—É. "
        "–°—Ç–∏–ª—å: –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π, –Ω–æ–≤–æ—Å—Ç–Ω–æ–π. –í—ã–≤–æ–¥–∏ —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç —Ç–µ–ª–∞ –±–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞."
    )
    user = f"–ó–∞–≥–æ–ª–æ–≤–æ–∫ (–∏—Å–ø–∞–Ω—Å–∫–∏–π): {title_es}\n\n–¢–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏ (–∏—Å–ø–∞–Ω—Å–∫–∏–π):\n{body_es[:8000]}"
    return [
        {"role": "system", "content": system},
        {"role": "user", "content": user},
    ]

def translate_and_summarize(title_es: str, body_es: str) -> tuple[str, str]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (title_ru, body_ru)
    """
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    # 1) –ö–æ—Ä–æ—Ç–∫–∏–π –ø–µ—Ä–µ–≤–æ–¥ –∑–∞–≥–æ–ª–æ–≤–∫–∞
    title_msg = [
        {"role": "system", "content": "–ü–µ—Ä–µ–≤–µ–¥–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å –∏—Å–ø–∞–Ω—Å–∫–æ–≥–æ –Ω–∞ —Ä—É—Å—Å–∫–∏–π –∫—Ä–∞—Ç–∫–æ –∏ —Ç–æ—á–Ω–æ. –í—ã–≤–µ–¥–∏ —Ç–æ–ª—å–∫–æ –ø–µ—Ä–µ–≤–æ–¥."},
        {"role": "user", "content": title_es.strip()[:300]}
    ]
    try:
        t = client.chat.completions.create(model=OPENAI_MODEL, messages=title_msg, temperature=0.2)
        title_ru = t.choices[0].message.content.strip()
    except Exception as e:
        log.warning(f"Title translation error: {e}")
        title_ru = title_es  # –µ—Å–ª–∏ —á—Ç–æ ‚Äî –æ—Å—Ç–∞–≤–∏–º –∫–∞–∫ –µ—Å—Ç—å

    # 2) –¢–µ–ª–æ
    try:
        m = client.chat.completions.create(model=OPENAI_MODEL, messages=build_prompt(title_es, body_es), temperature=0.2)
        body_ru = m.choices[0].message.content.strip()
    except Exception as e:
        log.warning(f"Body summarize error: {e}")
        body_ru = ""

    return title_ru, body_ru

# ---------------------------- FORMAT ----------------------------
def format_post(title_ru: str, body_ru: str, source_url: str) -> str:
    parts = []
    parts.append(f"<b>{html.escape(title_ru.strip())}</b>\n")
    if body_ru:
        parts.append(body_ru.strip())
    parts.append(f'\n\n<a href="{html.escape(source_url)}">–ß–∏—Ç–∞—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫</a>')
    parts.append(f'\n\n<a href="https://t.me/NoticiasEspanaHoy">–ù–æ–≤–æ—Å—Ç–∏ –ò—Å–ø–∞–Ω–∏—è üá™üá∏</a>')
    text = "\n".join(parts).strip()
    return text

def trim_for_caption(text: str, limit: int = 1024) -> str:
    if len(text) <= limit:
        return text
    # —Å—Ç–∞—Ä–∞–µ–º—Å—è –Ω–µ —Ä–µ–∑–∞—Ç—å —Ç–µ–≥–∏
    clean = re.sub(r"\s+", " ", text).strip()
    if len(clean) <= limit:
        return clean
    # –æ–±—Ä–µ–∂–µ–º –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—é
    ellipsis = "‚Ä¶"
    return clean[: limit - len(ellipsis)].rstrip() + ellipsis

# ---------------------------- PUBLISH ----------------------------
def post_to_channel(bot: Bot, text: str, image_url: str | None):
    try:
        if image_url:
            # –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π –¥–ª—è –ø–æ–¥–ø–∏—Å–∏ ‚Äî –æ—Ç–ø—Ä–∞–≤–∏–º –±–µ–∑ —Ñ–æ—Ç–æ
            caption = trim_for_caption(text, 1024)
            if len(text) == len(caption):
                bot.send_photo(
                    chat_id=CHANNEL,
                    photo=image_url,
                    caption=caption,
                    parse_mode=ParseMode.HTML,
                    disable_notification=True
                )
                return
        # –∏–Ω–∞—á–µ –ø—Ä–æ—Å—Ç–æ —Ç–µ–∫—Å—Ç
        bot.send_message(
            chat_id=CHANNEL,
            text=text,
            parse_mode=ParseMode.HTML,
            disable_web_page_preview=False,
            disable_notification=True
        )
    except Exception as e:
        log.error(f"Telegram send error: {e}")

# ---------------------------- PIPELINE ----------------------------
def process_entry(bot: Bot, entry):
    url = normalize_url(entry.get("link") or entry.get("id") or "")
    title = (entry.get("title") or "").strip()
    if not url or not title:
        return

    if seen(url, title):
        return

    article_text, image_url = extract_text(url)
    if not article_text:
        # –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç –Ω–µ –≤—ã—Ç–∞—â–∏–ª–∏ ‚Äî –ø–æ–ø—Ä–æ–±—É–µ–º —Ö–æ—Ç—è –±—ã –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑ RSS
        article_text = (entry.get("summary") or entry.get("description") or "").strip()

    if not article_text:
        return  # –Ω–µ—á–µ–≥–æ –ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å

    title_ru, body_ru = translate_and_summarize(title, article_text)
    if not title_ru:
        title_ru = title

    post_text = format_post(title_ru, body_ru, url)
    post_to_channel(bot, post_text, image_url)

    mark_seen(url, title)
    log.info(f"Published: {title_ru}")

def check_feeds_once(bot: Bot):
    for feed_url in RSS_FEEDS:
        try:
            f = feedparser.parse(feed_url)
            if not f.entries:
                continue
            # —Å–≤–µ–∂–∏–µ —Å–Ω–∞—á–∞–ª–∞ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 –∑–∞–ø–∏—Å–µ–π —Ö–≤–∞—Ç–∏—Ç)
            for e in list(f.entries)[-10:]:
                process_entry(bot, e)
        except Exception as e:
            log.warning(f"Feed error {feed_url}: {e}")

# ---------------------------- MAIN LOOP ----------------------------
async def scheduler():
    # Telegram bot
    tg_token = os.getenv("TELEGRAM_BOT_TOKEN")
    if not tg_token:
        raise RuntimeError("TELEGRAM_BOT_TOKEN is not set")
    if not os.getenv("OPENAI_API_KEY"):
        raise RuntimeError("OPENAI_API_KEY is not set")

    bot = Bot(token=tg_token)
    ensure_db()
    cleanup_db(days=7)

    log.info("Noticias Espa√±a Bot started")
    # —Å—Ç–∞—Ä—Ç–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ä–∞–∑—É
    check_feeds_once(bot)

    # –¥–∞–ª–µ–µ ‚Äî –ø–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é
    while True:
        await asyncio.sleep(CHECK_INTERVAL_MIN * 60)
        check_feeds_once(bot)
        cleanup_db(days=7)

def main():
    try:
        asyncio.run(scheduler())
    except KeyboardInterrupt:
        log.info("Stopped by user")

if __name__ == "__main__":
    main()
